{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d1452affa418d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "352b0f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clustering(n):\n",
    "\n",
    "    # load input data and labels\n",
    "    X_train = np.load('../../Datasets_Train_Test_Split/kryptonite-%s-X_train.npy' % (n))\n",
    "    y_train = np.load('../../Datasets_Train_Test_Split/kryptonite-%s-y_train.npy' % (n))\n",
    "    X_test = np.load('../../Datasets_Train_Test_Split/kryptonite-%s-X_test.npy' % (n))\n",
    "    y_test = np.load('../../Datasets_Train_Test_Split/kryptonite-%s-y_test.npy' % (n))\n",
    "\n",
    "    # Define parameter space for Gaussian Mixture Model\n",
    "    param_space = {\n",
    "        'n_components': (20, 50),\n",
    "        'covariance_type': ['full', 'tied', 'diag', 'spherical'],\n",
    "        'tol': (1e-4, 1e-2, 'log-uniform')\n",
    "    }\n",
    "\n",
    "    # Split data into class 0 and class 1\n",
    "    X_train_class0 = X_train[y_train == 0]\n",
    "    X_train_class1 = X_train[y_train == 1]\n",
    "\n",
    "    gmm = GaussianMixture()\n",
    "\n",
    "    # Train Gaussian Mixture Model for class 0\n",
    "    bayes_search_class0 = BayesSearchCV(\n",
    "        estimator = gmm,\n",
    "        search_spaces = param_space,\n",
    "        n_iter = 5,\n",
    "        cv = 4,\n",
    "        random_state = 42\n",
    "    )\n",
    "    bayes_search_class0.fit(X_train_class0)\n",
    "    best_gmm_class0 = bayes_search_class0.best_estimator_\n",
    "\n",
    "    # Train Gaussian Mixture Model for class 1\n",
    "    bayes_search_class1 = BayesSearchCV(\n",
    "        estimator = gmm,\n",
    "        search_spaces = param_space,\n",
    "        n_iter = 5,\n",
    "        cv = 4,\n",
    "        random_state = 42\n",
    "    )\n",
    "    bayes_search_class1.fit(X_train_class1)\n",
    "    best_gmm_class1 = bayes_search_class1.best_estimator_\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    log_likelihood_class0 = best_gmm_class0.score_samples(X_test)\n",
    "    log_likelihood_class1 = best_gmm_class1.score_samples(X_test)\n",
    "\n",
    "    # Predict the class with the highest log likelihood\n",
    "    y_pred = (log_likelihood_class1 > log_likelihood_class0).astype(int)\n",
    "\n",
    "    # Calculate the accuracy of the model\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30c1a7263641e676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for 9 features\n",
      "Test Accuracy: 0.9567\n",
      "Running for 12 features\n",
      "Test Accuracy: 0.5102\n",
      "Running for 15 features\n",
      "Test Accuracy: 0.4998\n",
      "Running for 18 features\n",
      "Test Accuracy: 0.5076\n"
     ]
    }
   ],
   "source": [
    "possible_n_vals = [9, 12, 15, 18]\n",
    "\n",
    "# Run clustering for different number of features\n",
    "for n_val in possible_n_vals:\n",
    "    print(f\"Running for {n_val} features\")\n",
    "    run_clustering(n_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
