{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.stats.contingency_tables import mcnemar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcnemar_test(y_true, y_pred_m1, y_pred_m2):\n",
    "    \"\"\"\n",
    "    Perform McNemar's test to compare the predictions of two models.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    y_true : np.ndarray\n",
    "        The ground truth labels for the dataset.\n",
    "    y_pred_m1 : np.ndarray\n",
    "        Predictions from the first model (e.g. logistic regression).\n",
    "    y_pred_m2 : np.ndarray\n",
    "        Predictions from the second model (e.g. decision tree, random forest, etc.).\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    float\n",
    "        The p-value from McNemar's test, indicating whether the two models' predictions\n",
    "        are statistically significantly different.\n",
    "\n",
    "    Notes:\n",
    "    -----\n",
    "    - McNemar's test uses a contingency table to compare the paired predictions:\n",
    "        [[both_correct + both_incorrect, model1_correct_model2_incorrect],\n",
    "         [model1_incorrect_model2_correct, 0]]\n",
    "    - Exact McNemar's test is used for small sample sizes.\n",
    "    - If the p-value is below a significance threshold (e.g., 0.05), it suggests that\n",
    "      the two models have statistically different performance.\n",
    "    \"\"\"\n",
    "    both_correct = np.sum((y_pred_m1 == y_true) & (y_pred_m2 == y_true))\n",
    "    # Logistic correct, Decision Tree incorrect\n",
    "    lr_correct_dt_incorrect = np.sum((y_pred_m1 == y_true) & (y_pred_m2 != y_true))\n",
    "    # Logistic incorrect, Decision Tree correct\n",
    "    lr_incorrect_dt_correct = np.sum((y_pred_m1 != y_true) & (y_pred_m2 == y_true))\n",
    "    # Both incorrect\n",
    "    both_incorrect = np.sum((y_pred_m1 != y_true) & (y_pred_m2 != y_true))\n",
    "\n",
    "    # Contingency table\n",
    "    contingency_table = np.array([[both_correct + both_incorrect, lr_correct_dt_incorrect],\n",
    "                                [lr_incorrect_dt_correct, 0]])\n",
    "\n",
    "    print(contingency_table)\n",
    "\n",
    "    # Perform McNemar test\n",
    "    result = mcnemar(contingency_table, exact=True).pvalue\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1835   77]\n",
      " [1688    0]]\n",
      "model:[rf], n: [9], McNemar p-val: [0.0]\n",
      "[[2473  130]\n",
      " [2197    0]]\n",
      "model:[rf], n: [12], McNemar p-val: [0.0]\n",
      "[[3091 1421]\n",
      " [1488    0]]\n",
      "model:[rf], n: [15], McNemar p-val: [0.22106191159593794]\n",
      "[[4478 1362]\n",
      " [1360    0]]\n",
      "model:[rf], n: [18], McNemar p-val: [0.9847082878742756]\n",
      "[[1836   76]\n",
      " [1688    0]]\n",
      "model:[nn], n: [9], McNemar p-val: [0.0]\n",
      "[[2350   81]\n",
      " [2369    0]]\n",
      "model:[nn], n: [12], McNemar p-val: [0.0]\n",
      "[[3047  113]\n",
      " [2840    0]]\n",
      "model:[nn], n: [15], McNemar p-val: [0.0]\n",
      "[[3650  113]\n",
      " [3437    0]]\n",
      "model:[nn], n: [18], McNemar p-val: [0.0]\n",
      "[[1848   79]\n",
      " [1673    0]]\n",
      "model:[cluster], n: [9], McNemar p-val: [0.0]\n",
      "[[2548  955]\n",
      " [1297    0]]\n",
      "model:[cluster], n: [12], McNemar p-val: [6.052485159065259e-13]\n",
      "[[3275 1381]\n",
      " [1344    0]]\n",
      "model:[cluster], n: [15], McNemar p-val: [0.49043076211320874]\n",
      "[[3823 1711]\n",
      " [1666    0]]\n",
      "model:[cluster], n: [18], McNemar p-val: [0.4489593312574476]\n"
     ]
    }
   ],
   "source": [
    "list_n = [9, 12, 15, 18]\n",
    "list_models = ['rf', 'nn', 'cluster']\n",
    "\n",
    "for model_name in list_models:\n",
    "    for n in list_n:\n",
    "        y_true = np.load('../../Datasets_Train_Test_Split/kryptonite-%s-y_test.npy' % n)\n",
    "        y_pred_m1 = np.load('../../Datasets_Train_Test_Split/kryptonite_%s_pred_%s.npy' % (n, 'logreg'))\n",
    "        y_pred_m2 = np.load('../../Datasets_Train_Test_Split/kryptonite_%s_pred_%s.npy' % (n, model_name))\n",
    "\n",
    "        p_value = mcnemar_test(y_true, y_pred_m1, y_pred_m2)\n",
    "        print(f'model:[{model_name}], n: [{n}], McNemar p-val: [{p_value}]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
