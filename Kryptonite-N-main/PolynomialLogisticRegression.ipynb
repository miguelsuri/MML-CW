{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "352b0f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_poly_logistic_regression(n, e):\n",
    "\n",
    "    X = np.load('Datasets/kryptonite-%s-X.npy'%(n))\n",
    "    y = np.load('Datasets/kryptonite-%s-y.npy'%(n))\n",
    "\n",
    "    # Shuffle and split the data\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.6, random_state=42)  # 60% training\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # 20% validation, 20% test\n",
    "\n",
    "    # Create polynomial features (set degree as desired)\n",
    "    degree = e\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_val_poly = poly.transform(X_val)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "    print(X_train_poly.shape)\n",
    "    features = X_train_poly.shape[-1]\n",
    "    print(\"Created features\")\n",
    "\n",
    "    # Initialize and fit logistic regression\n",
    "    logreg = LogisticRegression(max_iter=250, solver='sag', C=0.85, n_jobs=-1)\n",
    "    logreg.fit(X_train_poly, y_train)\n",
    "    print(\"Fit Model\")\n",
    "\n",
    "    # Evaluate on the validation set\n",
    "    y_val_pred = logreg.predict(X_val_poly)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    y_test_pred = logreg.predict(X_test_poly)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    return test_accuracy, features\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de79fcc9",
   "metadata": {},
   "source": [
    "### Pred for McNemar Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e594dad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\berma\\Documents\\Mathematics for Machine Learning\\MML-CW\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Model\n",
      "Test Accuracy: 0.5033\n",
      "18\n",
      "Fit Model\n",
      "Test Accuracy: 0.4985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\berma\\Documents\\Mathematics for Machine Learning\\MML-CW\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def run_poly_logistic_regression_fixed_datasets(n, e):\n",
    "\n",
    "    X_train = np.load('Datasets_McNemar_Test/kryptonite-%s-X_train.npy' % (n))\n",
    "    y_train = np.load('Datasets_McNemar_Test/kryptonite-%s-y_train.npy' % (n))\n",
    "    X_test = np.load('Datasets_McNemar_Test/kryptonite-%s-X_test.npy' % (n))\n",
    "    y_test = np.load('Datasets_McNemar_Test/kryptonite-%s-y_test.npy' % (n))\n",
    "\n",
    "\n",
    "    # Create polynomial features (set degree as desired)\n",
    "    degree = e\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "\n",
    "    # Initialize and fit logistic regression\n",
    "    logreg = LogisticRegression(max_iter=100, solver='sag', C=0.85)\n",
    "    logreg.fit(X_train_poly, y_train)\n",
    "    print(\"Fit Model\")\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    y_test_pred = logreg.predict(X_test_poly)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Save predictions for mcnemar test\n",
    "    np.save('Datasets_McNemar_Test/kryptonite_%s_pred_logreg.npy' % (n), y_test_pred)\n",
    "\n",
    "possible_n_vals = [9, 12, 15, 18]\n",
    "# possible_n_vals = [9, 12]\n",
    "possible_n_vals = [15, 18]\n",
    "\n",
    "\n",
    "for n in possible_n_vals:\n",
    "    print(n)\n",
    "    run_poly_logistic_regression_fixed_datasets(n=n, e=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccc3c57",
   "metadata": {},
   "source": [
    "### Visualization and Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d5f563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n:[9], e:[1]\n",
      "(7200, 10)\n",
      "Created features\n",
      "Fit Model\n",
      "Validation Accuracy: 0.4985\n",
      "Test Accuracy: 0.4941\n",
      "n:[9], e:[3]\n",
      "(7200, 220)\n",
      "Created features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Model\n",
      "Validation Accuracy: 0.5050\n",
      "Test Accuracy: 0.5193\n",
      "n:[9], e:[5]\n",
      "(7200, 2002)\n",
      "Created features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\berma\\Documents\\Mathematics for Machine Learning\\MML-CW\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Model\n",
      "Validation Accuracy: 0.5239\n",
      "Test Accuracy: 0.5283\n",
      "n:[9], e:[7]\n",
      "(7200, 11440)\n",
      "Created features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\berma\\Documents\\Mathematics for Machine Learning\\MML-CW\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Model\n",
      "Validation Accuracy: 0.6219\n",
      "Test Accuracy: 0.6115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [02:29<00:00, 37.43s/it]\u001b[A\n",
      " 25%|██▌       | 1/4 [02:29<07:29, 149.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n:[12], e:[1]\n",
      "(9600, 13)\n",
      "Created features\n",
      "Fit Model\n",
      "Validation Accuracy: 0.4983\n",
      "Test Accuracy: 0.4882\n",
      "n:[12], e:[3]\n",
      "(9600, 455)\n",
      "Created features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\berma\\Documents\\Mathematics for Machine Learning\\MML-CW\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Model\n",
      "Validation Accuracy: 0.5051\n",
      "Test Accuracy: 0.4993\n",
      "n:[12], e:[5]\n",
      "(9600, 6188)\n",
      "Created features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\berma\\Documents\\Mathematics for Machine Learning\\MML-CW\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Model\n",
      "Validation Accuracy: 0.5143\n",
      "Test Accuracy: 0.5143\n",
      "n:[12], e:[7]\n",
      "(9600, 50388)\n",
      "Created features\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "possible_n_vals = [9, 12, 15, 18]\n",
    "possible_e_vals = [1, 3, 5, 7]\n",
    "\n",
    "acc_by_n = []\n",
    "feat_by_n = []\n",
    "for n in tqdm(possible_n_vals):\n",
    "    single_n = []\n",
    "    single_feat = []\n",
    "    for e in tqdm(possible_e_vals):\n",
    "        print(f'n:[{n}], e:[{e}]')\n",
    "        acc, feat = run_poly_logistic_regression(n, e)\n",
    "        single_n.append(acc)\n",
    "        single_feat.append(feat)\n",
    "    acc_by_n.append(single_n)\n",
    "    feat_by_n.append(single_feat)\n",
    "\n",
    "print(acc_by_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e82dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_values = [9,12,15]\n",
    "\n",
    "p_values = [1,2,3,4,5,6,7]\n",
    "\n",
    "presolved_acc_by_n = [[0.5033918128654971, 0.516140350877193, 0.5139181286549708, 0.5250292397660818, 0.5383625730994152, 0.5638596491228071, 0.5913450292397661], \n",
    "                      [0.5016666666666667, 0.496875, 0.5058333333333334, 0.5108333333333334, 0.51375, 0.5241666666666667, 0.5333333333333333],\n",
    "                     [0.49773333333333336, 0.5005333333333334, 0.504, 0.4978666666666667, 0.5038666666666667, 0.5157333333333334, 0.5241666666666667]]\n",
    "\n",
    "presolved_feat_by_n = [[10, 55, 220, 715, 2002, 5005, 11440], \n",
    "                       [13, 91, 455, 1820, 6188, 18564, 50388],\n",
    "                       [16, 136, 816, 3876, 15504, 54264, 170544]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d662eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "n_values = [9, 12, 15]\n",
    "p_values = [1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "# Plot style\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_context(\"poster\", font_scale=1.5)\n",
    "colors = sns.color_palette(\"pastel\", 3)  # Pastel color palette\n",
    "\n",
    "success_hlines = [0.95, 0.925, 0.9]\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(30, 10), sharey=True)\n",
    "\n",
    "# Plot each n-value in its own subplot\n",
    "for i, (n, ax) in enumerate(zip(n_values, axes)):\n",
    "    ax.plot(presolved_feat_by_n[i], presolved_acc_by_n[i], marker='o', label=f'n = {n}', color=colors[i],\n",
    "           lw=7, markersize=20)\n",
    "    \n",
    "    # Annotating with p-values in the same color as the line\n",
    "    for j, (x, y) in enumerate(zip(presolved_feat_by_n[i], presolved_acc_by_n[i])):\n",
    "        ax.text(x, y+0.025, f'{p_values[j]}',  ha='right', va='bottom', color=colors[i])\n",
    "    \n",
    "    ax.axhline(success_hlines[i], color=colors[i], linestyle='--', lw=7)\n",
    "    # Customizing each subplot\n",
    "    ax.set_title(f'n = {n}')\n",
    "    ax.set_xlabel(\"Features\")\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"Accuracy\")\n",
    "    ax.set_xscale('log')\n",
    "    \n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.ylim((0.45, 1.0))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717cd40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "\n",
    "# Plot style\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_context(\"poster\", font_scale=1.5)\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "n = [9,12,15,18,24,30,45]\n",
    "succ = [0.95, 0.925, 0.9, 0.875, 0.8, 0.75, 0.7]\n",
    "plt.plot(n, succ, c='r')\n",
    "plt.scatter(x=n, y=succ, c='r') \n",
    "\n",
    "ax = plt.gca()\n",
    "# Annotating with p-values in the same color as the line\n",
    "for j, (x, y) in enumerate(zip(n, succ)):\n",
    "    ax.text(x, y+0.01, f'{succ[j]}',  ha='left', va='bottom', color='r', size=27)\n",
    "        \n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.ylim((0.6, 1.03))\n",
    "plt.xlim((7, 50))\n",
    "# Show the plot\n",
    "\n",
    "plt.title(\"Target Accuracies\")\n",
    "plt.ylabel(\"Acceptable Task Accuracy\")\n",
    "plt.xlabel(\"Feature Dimension of Kryptonite-n (n)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
